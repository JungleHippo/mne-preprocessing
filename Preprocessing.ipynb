{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import mne\n",
    "import json\n",
    "%matplotlib qt\n",
    "import os\n",
    "from mne_icalabel import label_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper function definitions\n",
    "def filter_raw(raw, order = 3):\n",
    "    '''\n",
    "    This function erases the first 5 seconds of the EEG, which include\n",
    "    the calibration period.\n",
    "    It then rereferences to the average of the channels.\n",
    "    Finally, it applies the following filters to an MNE raw object:\n",
    "    Band-pass from .5 to 50 Hz\n",
    "    Notch at 47-53, 97-103 & 147-153 for the elimination of industrial noise\n",
    "    and its harmonics.\n",
    "\n",
    "    All 4 filters are applied sequentially and are 3nd order Butterworth with \n",
    "    0 padding\n",
    "\n",
    "    Input: The raw object\n",
    "    Returns: None (since the raw object is passed by reference and changes are in-place)\n",
    "\n",
    "    '''\n",
    "\n",
    "    raw.crop(tmin=5.0)\n",
    "    raw = raw.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "    my_iir_params = dict(order=order, ftype='butter', output='ba', padlen=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    raw=raw.filter(l_freq=1, h_freq=100, method='iir', iir_params=my_iir_params)\n",
    "    raw=raw.filter(l_freq=53, h_freq=47, method='iir', iir_params=my_iir_params)\n",
    "    raw=raw.filter(l_freq=103, h_freq=97, method='iir', iir_params=my_iir_params)\n",
    "    raw=raw.filter(l_freq=153, h_freq=147, method='iir', iir_params=my_iir_params)\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change path in the next cell accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .EDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf(path, preload=True)\n",
    "rnet = mne.channels.make_standard_montage('brainproducts-RNP-BA-128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename channels according to our setup. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New eeg files (after around April 2022) -for old use next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate name correction\n",
    "mapping = {'POO1-0':'POO1', \n",
    "           'POO1-1':'POO10', \n",
    "           'XX-0':'FPZ', \n",
    "           'XX-1':'FCZ', \n",
    "           'XX-2':'AFF4', \n",
    "           'TPP1':'TPP10'}\n",
    "raw.rename_channels(mapping)\n",
    "\n",
    "# Drop trailing H from ch_names\n",
    "new_mapping = dict(zip(raw.ch_names, [ch.rstrip('H') for ch in raw.ch_names]))\n",
    "raw.rename_channels(new_mapping)\n",
    "rnet_fix_ch_names = [chan.upper().rstrip('H') for chan in rnet.ch_names]\n",
    "rnet.rename_channels(dict(zip(rnet.ch_names, rnet_fix_ch_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate name correction\n",
    "# mapping = {'POO1-0':'POO1', \n",
    "#            'POO1-1':'POO10', \n",
    "#            'FFC5-0':'FCC5', \n",
    "#            'FFC5-1':'FFC5', \n",
    "#            'XX-0':'FPZ', \n",
    "#            'XX-1':'FCZ', \n",
    "#            'XX-2':'AFF4', \n",
    "#            'TPP1':'TPP10'}\n",
    "\n",
    "# raw.rename_channels(mapping)\n",
    "\n",
    "# # Drop trailing H from ch_names\n",
    "# new_mapping = dict(zip(raw.ch_names, [ch.rstrip('H') for ch in raw.ch_names]))\n",
    "# raw.rename_channels(new_mapping)\n",
    "# rnet_fix_ch_names = [chan.upper().rstrip('H') for chan in rnet.ch_names]\n",
    "# rnet.rename_channels(dict(zip(rnet.ch_names, rnet_fix_ch_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.drop_channels([ch for ch in raw.ch_names if 'DC' in ch or 'GND' in ch])\n",
    "raw.set_montage(rnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_nihon(path, preload=True)\n",
    "\n",
    "# rescaling .eeg file\n",
    "for i, gain in enumerate(raw._raw_extras[0]['gains'][:,0]):\n",
    "    #print(raw.ch_names[i], gain, raw.__dict__['_data'][i,:50])\n",
    "    if gain == 0.001:\n",
    "        raw.__dict__['_data'][i] = (raw.__dict__['_data'][i]*0.0001)/raw._raw_extras[0]['cal'][i]\n",
    "        raw._raw_extras[0]['gains'][i,0] = 0.000001\n",
    "    elif gain == 0.000001:\n",
    "        raw.__dict__['_data'][i] = (raw.__dict__['_data'][i]*0.1)/raw._raw_extras[0]['cal'][i]\n",
    "\n",
    "# set montage\n",
    "rnet = mne.channels.make_standard_montage('brainproducts-RNP-BA-128')\n",
    "mapping = pd.read_csv('') # /path/to/channels.csv\n",
    "mapping = dict(zip(mapping.iloc[:,0].values, mapping.iloc[:,1].values))\n",
    "raw.rename_channels(mapping)\n",
    "\n",
    "raw.drop_channels([ch for ch in raw.ch_names if 'DC' in ch or 'GND' in ch])\n",
    "\n",
    "#change channel type\n",
    "mapping = {ch: 'eeg' for ch in raw.__dict__['info']['ch_names']}\n",
    "raw.set_channel_types(mapping)\n",
    "raw.set_montage(rnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marking bad channels. Standard interpolations are 'AFF4', 'FPZ', 'FCZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw.info['bads'] = ['AFF4', 'FPZ', 'FCZ']\n",
    "#raw.interpolate_bads(reset_bads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_raw(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual channel and time region rejection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, single channels significantly deviating from the butterfly plot (enable with pressing `b` in the plot window), should be marked as bad. Time regions also producing artifacts in multiple channels should be annotated with `BAD`. Do not regions with eye artifacts, either blinks or saccadic movements. Also inspect the PSD for indications of noisy channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For ICA a 99.99 % of components capturing the cumulative covariance are required. More than 70 components should appear in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting extended infomax for comparison with ICA Label\n",
    "ica = mne.preprocessing.ICA(n_components=.9999, method='infomax', fit_params=dict(extended=True), random_state=42 )\n",
    "ica.fit(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_sources(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = label_components(raw, ica, 'iclabel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred['y_pred_proba'])):\n",
    "    print(i, pred['labels'][i], pred['y_pred_proba'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw.plot(title=\"Before ICA\")\n",
    "appd = raw.copy()\n",
    "ica.apply(appd)\n",
    "#appd.plot(title=\"After ICA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appd.plot_psd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate channels not cleaned with ICA component removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appd.interpolate_bads(reset_bads=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a dictionary with bad channels and rejected ica components, the ICA and processed FIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather bad channels and rejected components into one dictionary\n",
    "bad_channels = raw.info['bads']\n",
    "rejected_components = ica.exclude\n",
    "#rejected_components =\n",
    "rejected_components.sort()\n",
    "rejections = {\n",
    "    \"bad_channels\": bad_channels,\n",
    "    \"rejected_components\": rejected_components\n",
    "}\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "for extension in ['_rejections.json', '-ica.fif', '_raw.fif']:\n",
    "    # Path Directory where the original file exists\n",
    "    path_arr = path.split(os.sep)\n",
    "    path_arr[-1] = path_arr[-1].split('.')[0] \n",
    "    path_arr[-1] += extension\n",
    "    new_path = os.path.join(*path_arr)\n",
    "    new_path = os.path.relpath(new_path)\n",
    "    if counter == 0:\n",
    "        # Rejections dictionary\n",
    "        with open(os.path.join(new_path), 'w') as f:\n",
    "            f.write(json.dumps(rejections, indent=4))\n",
    "\n",
    "    elif counter == 1:\n",
    "        ica.save(os.path.join(new_path))\n",
    "        print(new_path)\n",
    "        \n",
    "    elif counter == 2:\n",
    "        appd.save(os.path.join(new_path))\n",
    "    counter += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
